近年来状态空间模型（State Space Model, SSM）及其视觉扩展形式在序列建模和长程依赖捕获方面表现出较强优势，并逐步被引入视觉任务中。相关研究表明，基于状态空间模型的结构在保持线性计算复杂度的同时，具备良好的全局建模能力，为解决高分辨率图像场景下的效率瓶颈问题提供了新的技术路径。然而，现有将状态空间模型引入遥感语义分割的工作，多停留在注意力模块的替换或堆叠层面，未能充分挖掘状态空间模型与CNN的协同潜力。具体而言，现有方法普遍存在以下两方面不足：一是架构耦合问题，即全局上下文建模与局部细节提取在单一路径中堆叠处理，两类本质不同的任务共享相同的参数空间与计算流程，导致模型难以对任一任务实现最优建模；二是注意力冗余问题，即在网络中重复应用相似的注意力机制，虽在一定程度上增强了特征聚焦能力，但也带来了不必要的计算开销与参数冗余，影响了模型的整体效率。
针对上述问题，本文围绕“结构解耦—动态调制—协同融合”的设计思想，提出一种基于双路径解耦的遥感影像语义分割网络DP-UNet。该网络的核心思想在于将状态空间模型的全局语义建模优势与CNN的局部细节增强显式解耦为两条并行路径，使其能够在共享特征基础上分别进行针对性优化。具体而言，本文设计了解耦视觉状态空间（DVSS）模块作为解码器的核心组件：全局路径基于状态空间模型捕获长距离上下文依赖；局部路径引入高效通道注意力（Efficient Channel Attention, ECA）机制与轻量的参数调制卷积（Parameter-Modulated Convolution, PMC）模块，增强对细粒度空间结构的感知能力。两条路径的输出通过自适应路径融合门控（Adaptive Path Fusion Gate, APFG）模块进行动态加权融合，实现全局与局部信息的有效协同。此外，针对网络的注意力冗余问题，本文设计了轻量化的多尺度空间核（Multi-scale Spatial Kernel, MSK）模块，仅采用空间注意力进行跨尺度特征对齐，在保持性能的同时显著降低计算复杂度。
