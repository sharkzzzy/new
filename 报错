摘要—针对高分辨率遥感影像中地物尺度变化显著、目标边界模糊及传统注意力堆叠结构存在计算冗余与特征耦合过强等问题，本文提出一种基于双路径解耦与参数调制卷积的语义分割网络 DP-UNet。该网络采用"共享基础、分离增强"的设计思想，通过构建解耦视觉状态空间模块，在统一特征基础上设计并行的全局语义建模路径与局部细节增强路径，实现长距离依赖建模与局部空间结构刻画的协同优化。其中，全局路径基于状态空间模型提取全局上下文信息；局部路径引入高效通道注意力机制与参数调制卷积模块强化细节感知。为实现多路径特征的有效协同，设计自适应路径融合门控模块，对不同语义层次特征进行动态加权融合。此外，设计多尺度空间融合模块，通过多尺度卷积与空间注意力机制实现跨尺度特征对齐。在 ISPRS Potsdam、ISPRS Vaihingen 及 LoveDA 三个公开遥感数据集上的实验结果表明，所提出的 DP-UNet 在平均交并比（mIoU）、平均 F1 值（mF1）和总体精度（OA）等评价指标上均优于 CM-UNet、UNetFormer 等主流方法，验证了该方法在复杂遥感场景中的有效性与实用性。
关键词：遥感影像；语义分割；双路径解耦；状态空间模型
I. Introduction
随着对地观测技术的持续进步，高分辨率航空遥感和卫星遥感影像的获取能力不断提升，多源遥感数据呈现出规模化、高精度与高频次的发展趋势。遥感影像能够全面记录地表目标的光谱信息、空间结构特征以及纹理分布规律，为地表覆盖制图、生态环境评估、城市精细化管理和灾害风险监测等应用提供了重要的数据基础。在遥感图像智能分析任务中，语义分割作为一种典型的像素级理解方法，通过为影像中每一个像素赋予明确的语义标签，实现对地物类型的精细刻画与空间分布建模。由于遥感影像具备分辨率高、覆盖范围广和场景复杂度高等特点，语义分割技术已逐渐成为遥感信息智能解译领域的重要研究方向，并在土地利用/覆盖分类、城市扩展监测、交通设施提取、森林资源调查及水域变化分析等多个应用场景中展现出广泛的应用价值。
近年来，以卷积神经网络（Convolutional Neural Network, CNN）为代表的深度学习技术在计算机视觉领域取得了突破性进展，并逐步被引入遥感影像语义分割任务中。基于全卷积网络（Fully Convolutional Network, FCN）结构的发展，使得端到端的像素级分割成为可能。然而，高分辨率遥感影像在成像机理和目标分布方面的特殊性，使其呈现出显著的尺度变化和复杂的空间异质性：一方面，不同地物在空间尺度上差异明显，大尺度区域目标与小尺度目标在同一幅影像中共存，增加了特征建模难度；另一方面，不同类别之间在光谱表现上的相似性与类内差异性并存，导致模型易出现边界模糊和类别混淆问题。传统基于 CNN 的方法受限于固定大小的局部感受野，在建模长距离空间依赖关系时存在明显不足，难以在复杂遥感场景中同时兼顾全局语义一致性与局部细节精度。
为弥补 CNN 在全局信息建模方面的局限，近年来研究者开始将自注意力机制与 Transformer 结构引入遥感图像语义分割任务。相关研究表明，基于 Transformer 的模型能够通过全局建模机制有效捕获长程依赖关系，从而提升复杂场景下的语义一致性。然而，此类方法在高分辨率遥感影像场景中普遍面临计算开销较大的问题，其时间复杂度与空间复杂度均随分辨率呈二次增长，限制了其在大尺度遥感场景中的实际应用。此外，大多数 Transformer-based 模型仍依赖单一特征通路进行语义建模，其对局部结构信息的刻画能力有限，在处理细粒度边界和复杂结构地物时仍存在不足。
近年来状态空间模型（State Space Model, SSM）及其视觉扩展形式在序列建模和长程依赖捕获方面表现出较强优势，并逐步被引入视觉任务中。相关研究表明，基于状态空间模型的结构在保持线性计算复杂度的同时，具备良好的全局建模能力，为解决高分辨率图像场景下的效率瓶颈问题提供了新的技术路径。然而，现有将状态空间模型引入遥感语义分割的工作，多停留在
