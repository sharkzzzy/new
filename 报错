摘要：针对高分辨率遥感影像中地物尺度变化显著、目标边界模糊及传统注意力堆叠结构存在计算冗余与特征耦合过强等问题，本文提出一种基于双路径解耦与参数调制卷积的语义分割网络 DP-UNet。该网络编码器基于ResNet-18提取多层次特征，解码器采用"共享基础、分离增强"的设计思想，通过构建解耦视觉状态空间（DVSS）模块，在统一特征基础上设计并行的全局语义建模路径与局部细节增强路径，实现长距离依赖建模与局部空间结构刻画的协同优化。其中，全局路径基于状态空间模型提取全局上下文信息；局部路径引入高效通道注意力机制与参数调制卷积（PMC）模块强化细节感知。为实现多路径特征的有效协同，设计自适应路径融合门控（APFG）模块，对不同语义层次特征进行动态加权融合。此外，设计轻量化的多尺度空间融合模块，通过多尺度卷积与空间注意力机制实现跨尺度特征对齐，有效降低计算冗余。在 ISPRS Potsdam、ISPRS Vaihingen 及 LoveDA 三个公开遥感数据集上的实验结果表明，所提出的 DP-UNet 在平均交并比（mIoU）、平均 F1 值（mF1）和总体精度（OA）等评价指标上均优于 CM-UNet、UNetFormer 等主流方法，同时具备更低的计算开销，验证了该方法在复杂遥感场景中的有效性与实用性。
关键词：遥感影像；语义分割；双路径解耦；状态空间模型
英文论文名（小三 times）
姓名
摘要（小五 times）
关键词（小五 times）
 
随着对地观测技术的持续进步，高分辨率航空遥感和卫星遥感影像的获、取能力不断提升，多源遥感数据呈现出规模化、高精度与高频次的发展趋势。遥感影像能够全面记录地表目标的光谱信息、空间结构特征以及纹理分布规律，为地表覆盖制图、生态环境评估、城市精细化管理和灾害风险监测等应用提供了重要的数据基础。在遥感图像智能分析任务中，语义分割作为一种典型的像素级理解方法，通过为影像中每一个像素赋予明确的语义标签，实现对地物类型的精细刻画与空间分布建模。由于遥感影像具备分辨率高、覆盖范围广和场景复杂度高等特点，语义分割技术已逐渐成为遥感信息智能解译领域的重要研究方向，并在土地利用/覆盖分类、城市扩展监测、交通设施提取、森林资源调查及水域变化分析等多个应用场景中展现出广泛的应用价值。
近年来，以卷积神经网络（Convolutional Neural Network, CNN）为代表的深度学习技术在遥感影像语义分割任务中得到广泛应用。基于全卷积网络（Fully Convolutional Network, FCN）[1]结构的发展，使得端到端的像素级分割成为可能。此后，U-Net[2]通过编码器-解码器结构与跳跃连接机制实现了多尺度特征融合，DeepLabv3+[3]引入空洞空间金字塔池化模块增强了多尺度感知能力。然而，高分辨率遥感影像具有显著的尺度变化和复杂的空间异质性，不同地物在空间尺度上差异明显，且类间相似性与类内差异性并存，导致模型易出现边界模糊和类别混淆问题。传统CNN方法受限于局部感受野，难以在复杂遥感场景中同时兼顾全局语义一致性与局部细节精度。
为弥补CNN在全局信息建模方面的局限，研究者开始将Transformer结构引入遥感图像语义分割任务。Segmenter[4]采用纯Transformer架构实现了全局上下文建模，SegFormer[5]通过层次化编码器设计兼顾了多尺度特征提取与计算效率，BANet[6]利用双边注意力机制增强了边界感知能力，UNetFormer[7]则将Transformer与U-Net结构相结合，在遥感分割任务中取得了优异性能。然而，此类方法在高分辨率遥感影像场景中普遍面临计算开销较大的问题，其时间复杂度与空间复杂度均随分辨率呈二次增长，限制了其在大尺度遥感场景中的实际应用。
近年来，状态空间模型（State Space Model, SSM）及其视觉扩展形式在序列建模和长程依赖捕获方面表现出较强优势，并逐步被引入视觉任务中。在遥感领域，RS-Mamba[8]首次将状态空间模型引入遥感图像密集预测任务，验证了其在高分辨率场景下的有效性；Samba[9]采用双分支架构将Mamba与CNN相结合，尝试融合两者在全局建模与局部特征提取方面的优势。这些方法利用状态空间模型的线性复杂度优势实现了高效的全局建模。然而，现有工作多停留在注意力模块的替换或堆叠层面，未能充分挖掘两类模型的协同潜力。具体而言，现有方法普遍存在以下两方面不足：一是架构耦合问题，即全局上下文建模与局部细节提取在单一路径中堆叠处理，两类本质不同的任务共享相同的参数空间与计算流程，导致模型难以对任一任务实现最优建模；二是注意力冗余问题，即在网络中重复应用相似的注意力机制，虽在一定程度上增强了特征聚焦能力，但也带来了不必要的计算开销与参数冗余，影响了模型的整体效率。
针对上述问题，本文围绕“结构解耦—动态调制—协同融合”的设计思想，提出一种基于双路径解耦的遥感影像语义分割网络DP-UNet。该网络的核心思想在于将状态空间模型的全局语义建模优势与CNN的局部细节增强显式解耦为两条并行路径，使其能够在共享特征基础上分别进行针对性优化。具体而言，本文设计了解耦视觉状态空间（DVSS）模块作为解码器的核心组件：全局路径基于状态空间模型捕获长距离上下文依赖；局部路径引入高效通道注意力（Efficient Channel Attention, ECA）机制与轻量的参数调制卷积（Parameter-Modulated Convolution, PMC）模块，增强对细粒度空间结构的感知能力。两条路径的输出通过自适应路径融合门控（Adaptive Path Fusion Gate, APFG）模块进行动态加权融合，实现全局与局部信息的有效协同。此外，针对网络的注意力冗余问题，本文设计了轻量化的多尺度空间核（Multi-scale Spatial Kernel, MSK）模块，仅采用空间注意力进行跨尺度特征对齐，在保持性能的同时显著降低计算复杂度。本文的主要贡献总结如下：
1）提出了一种基于双路径解耦的遥感影像语义分割网络结构，显式分离全局语义建模路径与局部细节增强路径，在提升模型表达能力的同时有效降低计算冗余；
2）设计了一种轻量的参数调制卷积（PMC）模块，在卷积核参数空间引入动态抑制机制，增强模型对边界区域和细粒度目标的结构感知能力；
3）在ISPRS Potsdam、ISPRS Vaihingen和LoveDA三个公开遥感数据集上进行了充分的实验验证，结果表明本文方法在分割精度和计算效率方面均优于现有主流方法。 
。
 
 
图1  (a) Overall architecture of DP-UNet. The red arrows indicating upsampling and blue arrows indicating downsampling. (b) The baseline CSMamba block. (c) Our proposed DVSS block
 
1 Methodology
1.1整体网络架构
本文提出的DP-UNet采用经典的U型编码器-解码器结构，整体架构如图1所示。网络主要由三部分组成：基于ResNet-18的编码器、基于解耦视觉状态空间（DVSS）模块的解码器，以及用于多尺度特征融合的多尺度空间核（MSK）模块。
考虑到网络的轻量化，编码器采用在ImageNet上预训练的ResNet-18作为骨干网络，在四个不同尺度上输出特征图，分别对应原始输入分辨率的1/4、1/8、1/16和1/32，为后续解码器提供多层次特征表示。解码器是本文的核心创新所在。本文设计的DVSS模块采用双路径并行结构，将全局语义建模与局部细节增强显式解耦。DVSS模块的详细设计将在2.2节展开介绍。特征融合采用本文设计的MSK模块，通过多尺度卷积与空间注意力机制实现跨尺度特征对齐，详见2.3节。此外，网络在解码器各层输出端引入辅助监督机制，缓解深层网络的梯度传播困难，以提升训练稳定性。在推理阶段，仅使用最终输出层的预测结果。
1.2 解耦视觉状态空间模块（DVSS）
解耦视觉状态空间（Decoupled Visual State Space, DVSS）模块是本文解码器的核心组件，其结构如图1(c)所示。该模块的设计动机源于对现有方法中架构耦合问题的分析：全局上下文建模与局部细节提取本质上是两类不同的任务，在单一路径中串行处理会导致相互干扰，难以实现各自的最优建模。为此，DVSS模块采用"共享基础、分离增强"的设计理念，在统一的特征基础上构建两条并行的专用路径，分别针对全局语义建模与局部细节增强进行优化。
1.2.1 全局语义建模路径
给定输入特征 X∈R^(B×H×W×C) ，首先经过层归一化处理后，送入二维状态空间（SS2D）模块进行全局语义建模。
SS2D模块的核心是状态空间模型（State Space Model, SSM）。状态空间模型源于连续时间系统理论，通过将输入序列映射到隐状态空间进行建模，能够以线性计算复杂度捕获长距离依赖关系。其离散化形式可表示为：
h_t= A ̅h_{t-1} + B ̅x_t
y_t= Ch_t
其中，h_t为隐状态，x_t和y_t分别为输入和输出，A ̅、B ̅、C为可学习的状态转移参数。
针对二维图像特征，SS2D模块采用四方向扫描机制将空间建模问题转化为序列建模问题。具体而言，将二维特征图沿水平正向、水平反向、垂直正向、垂直反向四个方向分别展开为一维序列，对每个方向独立应用状态空间模型，最后将四个方向的输出特征进行聚合。这种多方向扫描策略能够全面捕获图像在不同空间方向上的上下文信息，克服单向扫描的方向偏置问题。
相比Transformer中的自注意力机制，状态空间模型具有线性计算复杂度的优势，能够以更低的计算代价实现全局依赖建模，这对于处理高分辨率遥感影像尤为重要。SS2D模块的输出作为全局路径特征 F_global ，同时也作为局部路径的输入，实现"共享基础、分离增强"的设计理念。
1.2.2 局部细节增强路径
局部路径以SS2D模块输出的共享特征为输入，通过一系列局部增强操作提取细粒度的空间结构信息。该路径包含两个核心组件：高效通道注意力（ECA）模块和参数调制卷积（PMC）模块。
首先，采用ECA机制对特征进行通道维度的自适应加权，增强有效通道的响应，抑制冗余信息。经ECA处理后的特征通过残差连接与输入相加，随后送入PMC模块进一步处理。
参数调制卷积（PMC）模块是本文设计的轻量化局部增强模块，其结构如图2(a)所示。该模块的核心思想是在卷积核的参数空间引入动态抑制机制，通过自适应调制卷积权重来增强模型对局部结构变化的感知能力。PMC模块的设计灵感来源于可学习变形卷积（Learnable Deformable Convolution），但将变形操作从空间域转移到参数域，避免了复杂的坐标偏移计算与双线性插值操作。
具体而言，给定标准卷积核的权重张量W，首先沿空间维度对其求和，生成通道强度矩阵S，用于表征每对输入-输出通道的重要性。然后，将可学习掩码矩阵W_m、固定中心掩码 M_c（中心位置值为1，其余为0）与通道强度矩阵 S相乘，生成动态掩码M_d。引入可学习缩放因子θ，按照以下公式对原始卷积权重进行调制：
W_eff=W⊙(B-θ×M_d )
其中，B 为全1张量，⊙ 表示逐元素乘法。调制后的有效权重 W_eff  用于对ECA模块输出的特征进行卷积操作。
该设计的核心作用在于动态抑制卷积核中心位置的响应强度，迫使网络学习更加分散、丰富的特征表示，减少对中心位置的过度依赖，从而有效增强模型对边界区域和细粒度目标的感知能力，同时保持极低的参数开销。局部路径的最终输出记为F_local。
为实现全局路径与局部路径特征的有效融合，本文设计了自适应路径融合门控（Adaptive Path Fusion Gate, APFG）模块，其结构如图2(b)所示。该模块的核心思想是根据特征内容自适应地调整两条路径的融合权重，而非简单的特征相加或拼接。具体而言，APFG模块首先对全局特征F_global和局部特征F_local分别进行全局平均池化，生成各自的通道描述子。然后，将两个描述子输入轻量化的权重生成网络，通过Softmax函数生成归一化的融合权重。最后，利用生成的权重对两条路径的特征进行加权求和：
F_{fused} = α⋅F_{global} + β⋅F_{local} 
其中，α和β为自适应生成的融合权重，满足α+β=1。
融合后的特征进一步通过残差连接与输入特征相加，并在训练过程中应用DropPath正则化策略，以增强模型的泛化能力。APFG模块的输出即为DVSS模块的最终输出，包含了全局上下文信息与局部细节特征的有效融合。
1.3 多尺度空间核模块（MSK）
多尺度空间核（Multi-scale Spatial Kernel, MSK）模块用于融合来自编码器不同尺度的特征，其结构如图3所示。在多尺度特征融合阶段，核心挑战在于弥合不同分辨率特征图之间的语义鸿沟与空间错位。考虑到DVSS模块的局部路径中已引入ECA模块进行通道注意力建模，为避免功能重复，MSK模块采用纯空间注意力的轻量化设计策略。
MSK模块的处理流程如下：首先，将来自编码器不同尺度的特征图 (F1,F2,F3)进行上采样对齐后在通道维度上拼接；然后，通过1×1卷积对拼接后的特征进行通道压缩，降低后续计算复杂度。
压缩后的特征被送入三个并行的卷积分支，分别采用  3×3、5×5, 和 7×7的卷积核进行多尺度空间特征提取，三个分支的输出逐元素相加进行融合。这种多尺度卷积设计能够同时捕获不同感受野范围内的空间信息，增强模型对多尺度目标的适应能力。
随后，通过空间注意力机制对融合特征进行增强。具体而言，沿通道轴分别进行平均池化和最大池化操作，将两个池化结果在通道维度上拼接后，通过7×7卷积层和Sigmoid激活函数生成空间注意力图，用于对多尺度融合特征进行空间维度上的加权，突出显著性区域的响应。最后，通过1×1卷积将特征通道数恢复至目标维度，得到MSK模块的输出。
该模块采用纯空间注意力设计，相比混合注意力机制具有更高的参数效率。以瓶颈层通道数 C^'=32为例，空间注意力仅包含一个  7×7卷积层（98个参数），而标准通道注意力模块需要约  C^'2 \/2个参数（约512个），参数量减少超过80%。
 
  
图2  (a) The workflow of the PMC module. (b) The structure of the APFG module. 
 
图3 The structure of the MSK module.
2 实验与分析
2.1 数据集与评价指标
为验证本文方法的有效性，在三个公开遥感影像语义分割数据集上进行实验，包括ISPRS Potsdam、ISPRS Vaihingen和LoveDA数据集。
ISPRS Potsdam数据集由德国Potsdam地区的高分辨率航空影像组成，空间分辨率为5cm。数据集包含6个语义类别：不透水面、建筑物、低矮植被、树木、汽车和背景。本文选取23幅影像用于训练（剔除标注存在问题的第7-10幅影像），14幅影像用于测试。
ISPRS Vaihingen数据集由德国Vaihingen地区的航空影像组成，空间分辨率为9cm，语义类别与Potsdam数据集相同。本文选取12幅影像用于训练，4幅影像用于测试。
LoveDA数据集是一个面向城乡场景的大规模遥感语义分割数据集，包含7个语义类别：背景、建筑物、道路、水体、荒地、森林和农田。该数据集涵盖城市和农村两种场景，具有更高的场景多样性和类别复杂度。本文使用1156幅训练影像和677幅测试影像进行实验。
评价指标方面，采用遥感语义分割领域常用的三个指标：平均交并比（mean Intersection over Union, mIoU）、平均F1值（mean F1-score, mF1）和总体精度（Overall Accuracy, OA）。其中，mIoU综合衡量分割结果与真实标签的重叠程度，是评价语义分割性能的核心指标。
2.2 实验设置
所有实验基于PyTorch深度学习框架实现，在NVIDIA RTX 3090 GPU上进行训练和测试。编码器采用在ImageNet上预训练的ResNet-18权重进行初始化，解码器部分随机初始化。
训练阶段采用AdamW优化器，初始学习率设置为6×10⁻⁴，并采用余弦退火策略进行学习率调整。输入影像随机裁剪为512×512像素的图像块，并采用多种数据增强策略，包括随机缩放（缩放比例0.5-1.5）、随机翻转、随机旋转以及亮度和对比度调整（调整幅度0.25，概率0.25）。所有输入影像均进行归一化处理。
测试阶段使用原始1024×1024分辨率的影像进行推理，并采用测试时翻转增强策略以提升预测精度。
2.3 对比实验结果
为全面评估本文方法的性能，选取多种代表性方法进行对比实验，包括：基于注意力机制的DANet、基于多分支结构的ABCNet、基于Transformer的Segmenter和BANet，以及近年来表现优异的UNetFormer和CM-UNet等。
2.3.1 ISPRS Potsdam数据集结果
表1展示了各方法在ISPRS Potsdam数据集上的定量结果。本文提出的DP-UNet取得了86.71%的mIoU、92.76%的mF1和91.57%的OA，在所有评价指标上均优于对比方法。具体而言，在"低矮植被"和"建筑物"等边界敏感类别上，DP-UNet表现出明显优势，能够生成轮廓更加清晰的分割结果。如图4所示，相比其他方法，DP-UNet在复杂边界区域的分割更加精确，有效减少了边界模糊和错分现象。
2.3.2 ISPRS Vaihingen数据集结果
表2展示了各方法在ISPRS Vaihingen数据集上的定量结果。DP-UNet取得了83.84%的mIoU、91.10%的mF1和91.43%的OA，同样在所有指标上达到最优。值得注意的是，在"汽车"类别上，DP-UNet取得了90.22%的F1值，相比其他方法具有明显优势。这一结果表明，本文设计的PMC模块能够通过动态权重调制有效增强对小目标的识别能力，实现更完整的小尺度目标分割。图5展示了部分可视化结果。
2.3.3 LoveDA数据集结果
表3展示了各方法在LoveDA数据集上的定量结果。该数据集场景更加多样，类别分布更加复杂，对模型的泛化能力提出了更高要求。DP-UNet取得了53.21%的mIoU，优于所有对比方法。在"建筑物"和"道路"等结构化类别上，DP-UNet表现尤为突出，分别取得了65.61%和55.05%的IoU。这一结果验证了全局语义建模路径与局部细节增强路径的有效协同，能够在复杂场景中实现更准确的地物分割。图6展示了部分可视化结果。
2.4 消融实验
为验证本文各模块设计的有效性，在LoveDA数据集上进行了详细的消融实验，实验采用1024×1024分辨率的影像进行评估。
2.4.1 核心模块有效性分析
为验证本文各模块设计的有效性，设计了一系列对比实验，结果如表4所示。实验通过构建不同的网络配置，分析各模块对分割性能与计算效率的影响。
（1）双路径解耦结构的有效性：对比配置A（单路径结构）与配置D（完整模型）可知，采用双路径解耦设计后mIoU从47.30%提升至53.21%，提升5.91个百分点。这一结果验证了将全局语义建模与局部细节增强显式分离的设计思想，使两类任务能够独立优化，充分发挥各自潜力。
（2）局部路径各组件的贡献：在完整模型基础上分别移除ECA模块（配置E）和PMC模块（配置F），分析其对性能的影响。结果表明，移除PMC模块后mIoU下降7.13个百分点（53.21%→46.08%），移除ECA模块后下降5.49个百分点（53.21%→47.72%）。这验证了两个模块对细粒度特征提取的协同增强作用，本文方法的高性能依赖于两者的有机配合。
（3）自适应融合策略的有效性：对比配置B（简单特征相加）与配置C（APFG自适应融合）的效果。采用简单相加时mIoU为51.16%，引入APFG模块后提升至52.44%，提升1.28个百分点。这表明自适应门控机制能够根据特征内容动态调整全局与局部路径的融合权重，优于固定权重的简单相加策略。
（4）MSK模块的有效性：对比配置C（采用混合注意力融合）与配置D（采用MSK模块）的效果。采用MSK模块后，推理速度从38.71 FPS提升至60.62 FPS（提升56.6%），同时mIoU从52.44%提升至53.21%。这一结果表明，当网络已具备专门的通道注意力模块（ECA）时，特征融合阶段采用纯空间注意力设计能够避免功能冗余，在提升效率的同时保持分割精度。
表5展示了本文方法与其他先进方法在模型复杂度方面的对比。DP-UNet在取得最优分割精度（53.21% mIoU）的同时，计算量仅为44.26G，参数量为11.30M，保持了较低的模型复杂度。相比其他高效模型如UNetFormer，DP-UNet在mIoU上提升3.49个百分点，而计算量相近，体现了良好的精度与效率平衡。
表1
EXPERIMENTAL RESULTS ON ISPRS POTSDAM DATASET
Method	Backbone	Imp.surf.	Building	Lowveg.	Tree	Car	mF1	OA	mIoU
DANet [10]
R18	91.02	95.63	86.14	87.64	84.32	88.92	89.12	80.38
ABCNet [11]
R18	93.28	95.91	86.78	87.81	95.49	91.85	90.51	85.17
Segmenter [12]
ViT-T	91.56	95.38	85.43	85.01	88.51	89.27	88.78	80.71
BANet [13]
ResT-L	93.36	96.70	87.48	89.11	96.05	92.55	91.01	86.36
UNetFormer[14]
R18	93.69	96.10	87.27	88.72	96.58	92.47	91.07	86.23
CM-UNet [4]
R18	93.62	96.49	87.42	88.51	96.09	92.43	91.04	86.15
DP-UNet	R18	94.10	96.70	87.78	89.13	96.09	92.76	91.57	86.71

 	 	 	 
 	 	 	 
(a)	(b)	(c)	(d)
 
图XX Qualitative performance comparisons on the ISPRS Potsdam. (a) NIRRG images, (b) UNet-Former, (c) CM-UNet, (d) DP-UNet. 

表XX
EXPERIMENTAL RESULTS ON ISPRRS VAIHINGEN DATASET
Method	Backbone	Imp.surf.	Building	Lowveg.	Tree	Car	mF1	OA	mIoU
DANet [10]
R18	90.07	93.95	82.21	87.31	44.52	79.67	88.24	69.46
ABCNet  [11]
R18	92.72	95.20	84.55	89.71	85.35	89.52	90.78	81.31
Segmenter  [12]
ViT-T	89.84	93.05	81.23	88.90	67.66	84.10	88.17	73.60
BANet  [13]
ResT-L	92.22	95.23	83.81	89.92	86.82	89.63	90.52	81.45
UNetFormer [14]
R18	93.07	95.42	85.03	90.74	88.99	90.65	91.21	83.09
CM-UNet  [4]
R18	93.09	95.75	85.02	90.70	89.86	90.89	91.26	83.49
DP-UNet	R18	93.18	95.88	85.37	90.84	90.22	91.10	91.43	83.84

 	 	 	 
 	 	 	 
(a)	(b)	(c)	(d)
 

图XXX Qualitative performance comparisons on the ISPRS Vaihingen. (a) NIRRG images, (b) UNet-Former, (c) CM-UNet, (d) DP-UNet. 
表XXX
EXPERIMENTAL RESULTS ON LOVEDA DATASET
Method	Backbone	Background	Building	Road	Water	Barren	Forest	Agriculture	mIoU
DeepLabV3+[15]
R50	43.02	50.92	52.04	74.43	10.40	44.21	58.59	47.65
BANet [13]
ResT-L	43.71	51.55	51.11	76.98	16.68	44.31	62.12	49.62
Segmenter [12]
ViT-T	38.03	50.74	48.76	77.40	13.36	43.48	58.20	47.18
ABCNet [11]
ViT-R50	53.00	62.18	52.42	62.02	29.80	41.61	47.27	49.80
UNetFormer [14]
R18	53.44	56.76	51.48	64.48	34.20	39.51	48.20	49.72
CM-UNet [4]
R18	55.65	62.70	53.56	65.73	34.90	42.17	54.17	52.84
DP-UNet	R18	54.99	65.61	55.05	67.83	32.52	44.70	51.73	53.21

 	 	 	 
 	 	 	 
(a)	(b)	(c)	(d)
 

图XXX Qualitative performance comparisons on the Loveda. (a) NIRRG images, (b) UNet-Former, (c) CM-UNet, (d) DP-UNet.

表  IV
ABLATION STUDY OF KEY COMPONENTS
Model Configuration	Architecture/Fusion	mIoU	FPS
A. Baseline: CM-UNet	Single-Path + MSAA	52.84	53.86
B. (A) - Remove SS2D-Attn	Simplified SS2D + MSAA	47.30	69.37
C. (B) + Detail-Branch	Dual-Path (Sum Fusion) + MSAA	51.16	46.35
C1. (B) + Detail-Branch +APFG	Dual-Path (w/ APFG) + MSAA	52.44	38.71
D. DP-UNet	Dual-Path (w/ APFG) +MSK	53.21	60.62
E. (D) - ECA	Dual-Path (w/ APFG) + MSK	47.72	62.38
F. (D) - PMC	Dual-Path (w/ APFG) + MSK	46.08	68.69

表 V
MODEL COMPLEXITY COMPARISON
Model	FLOPs(G)	FPS(fps)	Param.(M)	mIoU(%)
DeepLabV3+[15]
95.81	53.73	42.86	47.65
BANet [13]
52.65	11.51	12.74	49.62
Segmenter [12]
26.84	14.78	48.28	47.18
ABCNet [11]
123.43	29.36	13.42	49.80
UNetFormer[14]
46.94	115.33	11.75	49.72
CM-UNet [4]
48.04	53.86	12.89	52.84
DP-UNet	44.26	60.62	11.30	53.21
C. Further Analysis



3 Conclusion
本文提出了一种基于双路径解耦的遥感影像语义分割网络DP-UNet。该网络通过显式解耦的并行路径设计，有效融合了状态空间模型在全局建模方面的优势与卷积神经网络在局部特征提取方面的优势，同时采用轻量化的多尺度空间核模块进行特征融合，在保证分割精度的同时提升了计算效率。在三个公开遥感数据集上的实验表明，本文方法在分割精度与计算效率方面均优于现有先进方法，验证了双路径解耦设计的有效性与实用性。未来工作将从以下方面展开：一是探索双路径解耦思想在多模态遥感任务中的应用潜力；二是研究更轻量化的状态空间建模方法，进一步提升模型的实时性。
